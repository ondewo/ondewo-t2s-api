# ONDEWO T2S batch server configuration


inference:
    type: "composite"

    composite_inference:
        text2mel:
            type: "glow_tts"

            glow_tts:
                batch_size: 8
                use_gpu: false
                cleaners: []
                length_scale: 1.0
                noise_scale: 0.667
                path: "models/glow-tts/en/pretrained.pth"
                param_config_path: "models/glow-tts/en/config.json"

            glow_tts_triton:
                batch_size: 8
                length_scale: 1.0
                noise_scale: 0.667
                cleaners: []
                max_text_length: 100
                param_config_path: "models/glow-tts/de/config.json"
                triton_url: "localhost:8001"
                triton_model_name: "glow_tts"

        mel2audio:
            type: "hifi_gan"

            waveglow_triton:
                param_config_path: "models/waveglow/waveglow.yaml"
                sigma: 0.6
                max_spect_size: 1000
                triton_model_name: "waveglow"
                triton_url: "localhost:8001"

            mb_melgan_triton:
                config_path: "models/mb_melgan/en/config.yml"
                stats_path: "models/mb_melgan/en/stats.npy"
                triton_model_name: "mb_melgan"
                triton_url: "localhost:8001"

            hifi_gan:
                use_gpu: True
                batch_size: 20
                config_path: "models/HiFiGan/universal/config.json"
                model_path: "models/HiFiGan/universal/g_02500000"

    caching:
        active: false
        memory_cache_max_size: 20
        sampling_rate: 22050
        load_cache: true
        save_cache: true
        cache_save_dir: "models/cache"

normalization:
    language: "en"

    pipeline:

postprocessing:
    silence_secs: 0.25

    pipeline:
        - "apodization"

    apodization:
        apodization_secs: 0.5