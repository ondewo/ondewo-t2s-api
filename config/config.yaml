# ONDEWO T2S batch server configuration


inference:
    type: "composite"

    composite_inference:
        text2mel:
            type: "tacotron2"

            tacotron2:
                batch_size: 8
                path: "models/tacotron2/de/kerstin_PUN/"
                param_config_path: "models/tacotron2/de/tacotron2.yaml"
                step: "1000"

        mel2audio:
            type: "mb_melgan"

            waveglow:
                batch_size: 4
                path: "models/waveglow/pretrained/WaveGlowNM.pt"
                param_config_path: "models/waveglow/waveglow.yaml"
                sigma: 0.6
                denoiser:
                    active: true
                    strength: 0.05

            waveglow_triton:
                param_config_path: "models/waveglow/waveglow.yaml"
                sigma: 0.6
                max_spect_size: 1000
                triton_model_name: "waveglow"
                triton_url: "localhost:8001"

            mb_melgan:
                config_path: "models/mb_melgan/en/config.yml"
                model_path: "models/mb_melgan/en/generator-680000.h5"
                stats_path: "models/mb_melgan/en/stats.npy"

    caching:
        active: false
        memory_cache_max_size: 20
        sampling_rate: 22050
        load_cache: true
        save_cache: true
        cache_save_dir: "models/cache"