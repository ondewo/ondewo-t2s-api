# ONDEWO T2S batch server configuration


inference:
    type: "composite"

    composite_inference:
        text2mel:
            type: "glow_tts"

            glow_tts:
                batch_size: 8
                use_gpu: false
                cleaners: []
                length_scale: 1.0
                noise_scale: 0.667
                batch_inference: false
                path: "models/glow-tts/en/pretrained.pth"
                param_config_path: "models/glow-tts/en/config.json"

        mel2audio:
            type: "mb_melgan_tf"

            mb_melgan_tf:
                batch_size: 20
                config_path: "models/mb_melgan/en/config.yml"
                model_path: "models/mb_melgan/en/generator-680000.h5"
                stats_path: "models/mb_melgan/en/stats.npy"

    caching:
        active: false
        memory_cache_max_size: 20
        sampling_rate: 22050
        load_cache: true
        save_cache: true
        cache_save_dir: "models/cache"

normalization:
    language: "en"

    pipeline:

postprocessing:
    silence_secs: 0.25

    pipeline:
        - "apodization"

    apodization:
        apodization_secs: 0.5