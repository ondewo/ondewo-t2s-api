{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell only once after kernel started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure you are in \"ondewo-t2s-client-python\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fcavallin/ondewo/ondewo-t2s'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import soundfile as sf\n",
    "import IPython.display as ipd\n",
    "import grpc\n",
    "from ondewo_grpc.ondewo.t2s import text_to_speech_pb2, text_to_speech_pb2_grpc\n",
    "import google.protobuf.empty_pb2 as empty_pb2\n",
    "from google.protobuf.json_format import ParseDict, MessageToDict, MessageToJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the parameters of the grpc server. The example below is for the case when server is running locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MESSAGE_LENGTH: int = 60000000\n",
    "GRPC_HOST: str = \"localhost\"\n",
    "GRPC_PORT: str = \"50555\"\n",
    "CHANNEL: str = f\"{GRPC_HOST}:{GRPC_PORT}\"\n",
    "\n",
    "options = [\n",
    "    ('grpc.max_send_message_length', MAX_MESSAGE_LENGTH),\n",
    "    ('grpc.max_receive_message_length', MAX_MESSAGE_LENGTH),\n",
    "]\n",
    "\n",
    "\n",
    "channel = grpc.insecure_channel(CHANNEL, options=options)\n",
    "stab = text_to_speech_pb2_grpc.Text2SpeechStub(channel=channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all t2s pipelines present on the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = stab.ListT2sPipelines(request=empty_pb2.Empty()).pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select pipelines for specific language language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pipeline_for_language(pipelines, language):\n",
    "    for pipeline in pipelines:\n",
    "        if pipeline.description.language == language:\n",
    "            return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_pipeline = find_pipeline_for_language(pipelines=pipelines, language='en')\n",
    "german_pipeline = find_pipeline_for_language(pipelines=pipelines, language='de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"glow_tts&hifi_gan-0118e07a-8447-4c87-9f6b-4802a7dd7a07\"\n",
       "description {\n",
       "  language: \"en\"\n",
       "  speaker_sex: \"female\"\n",
       "  pipeline_owner: \"ondewo\"\n",
       "  comments: \"trained on public domain dataset Lj_speech\"\n",
       "  speaker_name: \"Linda\"\n",
       "  domain: \"general\"\n",
       "}\n",
       "active: true\n",
       "inference {\n",
       "  type: \"composite\"\n",
       "  composite_inference {\n",
       "    text2mel {\n",
       "      type: \"glow_tts\"\n",
       "      glow_tts {\n",
       "        batch_size: 5\n",
       "        use_gpu: true\n",
       "        length_scale: 1.0\n",
       "        noise_scale: 0.6669999957084656\n",
       "        path: \"models/glow-tts/en/pretrained.pth\"\n",
       "        param_config_path: \"models/glow-tts/en/config.json\"\n",
       "      }\n",
       "      glow_tts_triton {\n",
       "        batch_size: 8\n",
       "        length_scale: 1.0\n",
       "        noise_scale: 0.6669999957084656\n",
       "        max_text_length: 100\n",
       "        param_config_path: \"models/glow-tts/en/config.json\"\n",
       "        triton_url: \"localhost:50511\"\n",
       "        triton_model_name: \"glow_tts\"\n",
       "      }\n",
       "    }\n",
       "    mel2audio {\n",
       "      type: \"hifi_gan\"\n",
       "      mb_melgan_triton {\n",
       "        config_path: \"models/mb_melgan/en/config.yml\"\n",
       "        stats_path: \"models/mb_melgan/en/stats.npy\"\n",
       "        triton_model_name: \"mb_melgan\"\n",
       "        triton_url: \"localhost:50511\"\n",
       "      }\n",
       "      hifi_gan {\n",
       "        use_gpu: true\n",
       "        batch_size: 20\n",
       "        config_path: \"models/HiFiGan/universal/config.json\"\n",
       "        model_path: \"models/HiFiGan/universal/g_02500000\"\n",
       "      }\n",
       "      hifi_gan_triton {\n",
       "        config_path: \"models/HiFiGan/universal/config.json\"\n",
       "        triton_model_name: \"hifi_tts\"\n",
       "        triton_url: \"localhost:50511\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  caching {\n",
       "    memory_cache_max_size: 20\n",
       "    sampling_rate: 22050\n",
       "    load_cache: true\n",
       "    save_cache: true\n",
       "    cache_save_dir: \"models/cache\"\n",
       "  }\n",
       "}\n",
       "normalization {\n",
       "  language: \"en\"\n",
       "}\n",
       "postprocessing {\n",
       "  silence_secs: 0.25\n",
       "  logmmse {\n",
       "    initial_noise: 100\n",
       "    noise_threshold: 0.15000000596046448\n",
       "  }\n",
       "  wiener {\n",
       "    frame_len: 1024\n",
       "    lpc_order: 50\n",
       "    iterations: 10\n",
       "    alpha: 0.5\n",
       "    thresh: 0.10000000149011612\n",
       "  }\n",
       "  apodization {\n",
       "    apodization_secs: 0.25\n",
       "  }\n",
       "}\n",
       ", id: \"glow_tts&hifi_gan-e976dd6c-2f41-484b-aec2-3e6868d37290\"\n",
       "description {\n",
       "  language: \"de\"\n",
       "  speaker_sex: \"female\"\n",
       "  pipeline_owner: \"ondewo\"\n",
       "  comments: \"trained on public domain dataset\"\n",
       "  speaker_name: \"Kerstin\"\n",
       "  domain: \"general\"\n",
       "}\n",
       "active: true\n",
       "inference {\n",
       "  type: \"composite\"\n",
       "  composite_inference {\n",
       "    text2mel {\n",
       "      type: \"glow_tts\"\n",
       "      glow_tts {\n",
       "        batch_size: 5\n",
       "        length_scale: 1.0\n",
       "        noise_scale: 0.6669999957084656\n",
       "        path: \"models/glow-tts/de/kerstin_blank.pth\"\n",
       "        param_config_path: \"models/glow-tts/de/config_blank.json\"\n",
       "      }\n",
       "      glow_tts_triton {\n",
       "        batch_size: 8\n",
       "        length_scale: 1.0\n",
       "        noise_scale: 0.6669999957084656\n",
       "        max_text_length: 100\n",
       "        param_config_path: \"models/glow-tts/de/config_blank.json\"\n",
       "        triton_url: \"localhost:50511\"\n",
       "        triton_model_name: \"glow_tts\"\n",
       "      }\n",
       "    }\n",
       "    mel2audio {\n",
       "      type: \"hifi_gan\"\n",
       "      mb_melgan_triton {\n",
       "        config_path: \"models/mb_melgan/en/config.yml\"\n",
       "        stats_path: \"models/mb_melgan/en/stats.npy\"\n",
       "        triton_model_name: \"mb_melgan\"\n",
       "        triton_url: \"localhost:50511\"\n",
       "      }\n",
       "      hifi_gan {\n",
       "        batch_size: 20\n",
       "        config_path: \"models/HiFiGan/universal/config.json\"\n",
       "        model_path: \"models/HiFiGan/universal/g_02500000\"\n",
       "      }\n",
       "      hifi_gan_triton {\n",
       "        config_path: \"models/HiFiGan/universal/config.json\"\n",
       "        triton_model_name: \"hifi_tts\"\n",
       "        triton_url: \"localhost:50511\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  caching {\n",
       "    memory_cache_max_size: 20\n",
       "    sampling_rate: 22050\n",
       "    load_cache: true\n",
       "    save_cache: true\n",
       "    cache_save_dir: \"models/cache\"\n",
       "  }\n",
       "}\n",
       "normalization {\n",
       "  language: \"de\"\n",
       "  pipeline: \"fix_plus\"\n",
       "  pipeline: \"normalize_urls\"\n",
       "  pipeline: \"normalize_dates\"\n",
       "  pipeline: \"normalize_year\"\n",
       "  pipeline: \"normalize_time\"\n",
       "  pipeline: \"normalize_numbers\"\n",
       "  pipeline: \"remove_unaudible_texts\"\n",
       "  pipeline: \"lower_case\"\n",
       "}\n",
       "postprocessing {\n",
       "  silence_secs: 0.25\n",
       "  logmmse {\n",
       "    initial_noise: 100\n",
       "    noise_threshold: 0.15000000596046448\n",
       "  }\n",
       "  wiener {\n",
       "    frame_len: 1024\n",
       "    lpc_order: 50\n",
       "    iterations: 10\n",
       "    alpha: 0.5\n",
       "    thresh: 0.10000000149011612\n",
       "  }\n",
       "  apodization {\n",
       "    apodization_secs: 0.25\n",
       "  }\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make synthesize request to the server to get audio for given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Protocol message SynthesizeRequest has no \"t2s_pipeline_id\" field.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_167229/1767398367.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_speech_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSynthesizeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'magic_word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2s_pipeline_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgerman_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_format\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSynthesize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Length of the generated audio is {response.audio_length} sec.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'Generation time is {response.generation_time} sec.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Protocol message SynthesizeRequest has no \"t2s_pipeline_id\" field."
     ]
    }
   ],
   "source": [
    "request = text_to_speech_pb2.SynthesizeRequest(text='magic_word', t2s_pipeline_id=german_pipeline.id, length_scale = 1.0, pcm=0, audio_format= 0)\n",
    "response = stab.Synthesize(request=request)\n",
    "print(f'Length of the generated audio is {response.audio_length} sec.', f'Generation time is {response.generation_time} sec.')\n",
    "\n",
    "bio = io.BytesIO(response.audio)\n",
    "\n",
    "audio = sf.read(bio, )\n",
    "\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = text_to_speech_pb2.SynthesizeRequest(text='CT', t2s_pipeline_id=german_pipeline.id, length_scale = 1)\n",
    "response = stab.Synthesize(request=request)\n",
    "\n",
    "print(f'Length of the generated audio is {response.audio_length} sec.', f'Generation time is {response.generation_time} sec.')\n",
    "\n",
    "bio = io.BytesIO(response.audio)\n",
    "\n",
    "audio = sf.read(bio)\n",
    "\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding length scale parameter to make speech faster or slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = text_to_speech_pb2.SynthesizeRequest(text='Hi, how are you?', t2s_pipeline_id=english_pipeline.id, length_scale=0.5)\n",
    "response = stab.Synthesize(request=request)\n",
    "\n",
    "print(f'Length of the generated audio is {response.audio_length} sec.', f'Generation time is {response.generation_time} sec.')\n",
    "\n",
    "bio = io.BytesIO(response.audio)\n",
    "\n",
    "audio = sf.read(bio)\n",
    "\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pipeline you want to update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = text_to_speech_pb2.T2sPipelineId(id=english_pipeline.id)\n",
    "pipeline_config = stab.GetT2sPipeline(request=request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change parameter in the pipeline config. For example default length scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.inference.composite_inference.text2mel.glow_tts.length_scale = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stab.UpdateT2sPipeline(request=pipeline_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See if generated audio change according to updated config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = text_to_speech_pb2.SynthesizeRequest(text='Hi, how are you?', t2s_pipeline_id=english_pipeline.id)\n",
    "response = stab.Synthesize(request=request)\n",
    "\n",
    "print(f'Length of the generated audio is {response.audio_length} sec.', f'Generation time is {response.generation_time} sec.')\n",
    "\n",
    "bio = io.BytesIO(response.audio)\n",
    "\n",
    "audio = sf.read(bio)\n",
    "\n",
    "ipd.Audio(audio[0], rate=audio[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change parameter back to previous (length_scale = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = text_to_speech_pb2.T2sPipelineId(id=english_pipeline.id)\n",
    "pipeline_config = stab.GetT2sPipeline(request=request)\n",
    "pipeline_config.inference.composite_inference.text2mel.glow_tts.length_scale = 1.0\n",
    "stab.UpdateT2sPipeline(request=pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['f', 'k']\n",
    "from uuid import UUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(hash(str(l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UUID(bytes=b'kk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from normalization.custom_phonemizer_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
