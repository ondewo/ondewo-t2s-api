// Copyright 2020 ONDEWO GmbH
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package ondewo.t2s;
import "google/protobuf/empty.proto";
import "google/protobuf/struct.proto";

// <p>Text2Speech service provides endpoints for text-to-speech generation.</p>
service Text2Speech {

    // <p>Synthesizes a specific text sent in the request with the provided configuration requirements
    // and retrieves a response that includes the synthesized text as audio and the requested configuration.</p>
    rpc Synthesize(SynthesizeRequest) returns (SynthesizeResponse);

    // <p>Performs batch synthesis by accepting a batch of synthesis requests and returning a batch response.
    // This can be more efficient for generating predictions on the AI model in bulk.</p>
    rpc BatchSynthesize(BatchSynthesizeRequest) returns (BatchSynthesizeResponse);

    // <p>Performs streaming synthesis by accepting stream of input text and returning a stream of generated audio.</p>
    rpc StreamingSynthesize(stream StreamingSynthesizeRequest) returns (stream StreamingSynthesizeResponse);

    // <p>Normalizes a text according to the specific pipeline&apos;s normalization rules.</p>
    rpc NormalizeText(NormalizeTextRequest) returns (NormalizeTextResponse);

    // <p>Retrieves the configuration of the specified text-to-speech pipeline.</p>
    rpc GetT2sPipeline(T2sPipelineId) returns (Text2SpeechConfig);

    // <p>Creates a new text-to-speech pipeline with the provided configuration and returns its pipeline ID.</p>
    rpc CreateT2sPipeline(Text2SpeechConfig) returns (T2sPipelineId);

    // <p>Deletes the specified text-to-speech pipeline.</p>
    rpc DeleteT2sPipeline(T2sPipelineId) returns (google.protobuf.Empty);

    // <p>Updates the specified text-to-speech pipeline with the given configuration.</p>
    rpc UpdateT2sPipeline(Text2SpeechConfig) returns (google.protobuf.Empty);

    // <p>Retrieves a list of text-to-speech pipelines based on specific requirements.</p>
    rpc ListT2sPipelines(ListT2sPipelinesRequest) returns (ListT2sPipelinesResponse);

    // <p>Retrieves a list of languages available based on specific configuration requirements.</p>
    rpc ListT2sLanguages(ListT2sLanguagesRequest) returns (ListT2sLanguagesResponse);

    // <p>Retrieves a list of domains available based on specific configuration requirements.</p>
    rpc ListT2sDomains(ListT2sDomainsRequest) returns (ListT2sDomainsResponse);

    // <p>Retrieves a list of normalization pipelines based on specific requirements.</p>
    rpc ListT2sNormalizationPipelines(ListT2sNormalizationPipelinesRequest) returns (ListT2sNormalizationPipelinesResponse);

    // <p>Retrieves the version information of the running text-to-speech server.</p>
    rpc GetServiceInfo(google.protobuf.Empty) returns (T2SGetServiceInfoResponse);

    // <p>Retrieves a custom phonemizer based on the provided PhonemizerId.</p>
    rpc GetCustomPhonemizer(PhonemizerId) returns (CustomPhonemizerProto);

    // <p>Creates a custom phonemizer based on the provided CreateCustomPhonemizerRequest.
    // Returns the PhonemizerId associated with the created custom phonemizer.</p>
    rpc CreateCustomPhonemizer(CreateCustomPhonemizerRequest) returns (PhonemizerId);

    // <p>Deletes a custom phonemizer based on the provided PhonemizerId.
    // Returns an Empty response upon successful deletion.</p>
    rpc DeleteCustomPhonemizer(PhonemizerId) returns (google.protobuf.Empty);

    // <p>Updates the specified custom phonemizer with the provided configuration.</p>
    rpc UpdateCustomPhonemizer(UpdateCustomPhonemizerRequest) returns (CustomPhonemizerProto);

    // <p>Retrieves a list of custom phonemizers based on specific requirements.</p>
    rpc ListCustomPhonemizer(ListCustomPhonemizerRequest) returns (ListCustomPhonemizerResponse);
}

// <p>Represents a Synthesize Request.</p>
// <p>A Synthesize Request contains the information need to perform a text to speech conversion.</p>
message SynthesizeRequest {

    // Required. Represents the text that will be transformed to speech.
    // Synthesize text:
    // <ul>
    //   <li>Simple text: <pre><code>Hello, how are you?</code></pre></li>
    // </ul>
    // Examples to modulate the voice based on SSML tags and Arpabet phonemes:
    // <ul>
    //   <li>SSML Tag Phone: <pre><code>&lt;say-as interpret-as=&quot;phone&quot;&gt;+12354321&lt;/say-as&gt;</code></pre></li>
    //   <li>SSML Tag Email: <pre><code>&lt;say-as interpret-as=&quot;email&quot;&gt;voices@ondewo.com&lt;/say-as&gt;</code></pre></li>
    //   <li>SSML Tag URL: <pre><code>&lt;say-as interpret-as=&quot;url&quot;&gt;ondewo.com/en/&lt;/say-as&gt;</code></pre></li>
    //   <li>SSML Tag Spell: <pre><code>&lt;say-as interpret-as=&quot;spell&quot;&gt;AP732&lt;/say-as&gt;</code></pre></li>
    //   <li>SSML Tag Spell With Names: <pre><code>&lt;say-as interpret-as=&quot;spell-with-names&quot;&gt;AHO32&lt;/say-as&gt;</code></pre></li>
    //   <li>SSML Tag Callsigns Short: <pre><code>&lt;say-as interpret-as=&quot;callsign-short&quot;&gt;AUA439&lt;/say-as&gt;</code></pre></li>
    //   <li>SSML Tag Callsigns Long: <pre><code>&lt;say-as interpret-as=&quot;callsign-long&quot;&gt;AAL439&lt;/say-as&gt;</code></pre></li>
    //   <li>SSML Tag Break Tag: <pre><code>I am going to take a 2 seconds break &lt;break time=&quot;2.0&quot;/&gt; done</code></pre></li>
    //   <li>Arpabet Phonemes: <pre><code>Hello I am {AE2 L EH0 G Z AE1 N D R AH0}</code></pre></li>
    // </ul>
    string text = 1;

    // Required. Represents the specifications needed to do the text to speech transformation.
    RequestConfig config = 2;

}

// <p>BatchSynthesizeRequest message is used to send a batch request for synthesis.</p>
message BatchSynthesizeRequest {

    // Repeated field holding individual synthesis requests that make up the batch request.
    repeated SynthesizeRequest batch_request = 1;
}

// <p>StreamingSynthesizeRequest is used to perform streaming synthesize.</p>
message StreamingSynthesizeRequest {

    // Required. Represents the text that will be transformed to speech.
    // All the properties according to the input text in SynthesizeRequest can be also applied here.
    string text = 1;

    // Required. Represents the specifications needed to do the text to speech transformation.
    RequestConfig config = 2;

}

// <p>BatchSynthesizeResponse message is used to store the responses for a batch synthesis request.</p>
message BatchSynthesizeResponse {

    // Repeated field holding individual synthesis responses that correspond to the input requests in the batch.
    repeated SynthesizeResponse batch_response = 1;
}

// <p>Represents a Configuration for the text to speech conversion.</p>
message RequestConfig {

    // Required. Represents the pipeline id of the model configuration that will be used.
    string t2s_pipeline_id = 1;

    oneof oneof_length_scale {
        // Optional. This parameter is used for time stretching which is the process of
        // changing the speed or duration of an audio.
        // It should be much more than 1.0. O is not a valid number for this variable.
        // The default value is 1.
        float length_scale = 2;
    }

    oneof  oneof_noise_scale {
        // Optional. Defines the noise in the generated audio.
        // It should be between 0.0 and 1.
        // The default value is 0.0
        float noise_scale = 3;
    }

    oneof oneof_sample_rate {
        // Optional. Defines the sample rate of the generated wav file.
        // The default value is 22050.
        int32 sample_rate = 4;
    }

    oneof oneof_Pcm {
        // Optional. Defines the pulse-code modulation of the wav file.
        // The default value is PCM_16.
        Pcm pcm = 5;
    }

    oneof oneof_AudioFormat {
        // Optional. Defines the format of the desired audio.
        // The default value is wav.
        AudioFormat audio_format = 6;
    }

    oneof oneof_use_cache {
        // Optional. Define if cache should be used or not.
        // The default value is False.
        bool use_cache = 7;
    }

    reserved 8;
    reserved "normalizer";

    // Optional. t2s_service_config provides the configuration of the service such as API key, bearer tokens, JWT,
    // and other header information as key value pairs, e.g., <pre><code>MY_API_KEY=&apos;LKJDIFe244LKJOI&apos;</code></pre>
    //
    // A. For Amazon T2S service, the following arguments should be passed:
    // <ul>
    //   <li>A1. <code>aws_access_key_id</code> (required) Access key id to access Amazon WEB Service.</li>
    //   <li>A2. <code>aws_secret_access_key</code> (required) Secret access key to access Amazon WEB Service.</li>
    //   <li>A3. <code>region</code> (required) Region name of Amazon Server.</li>
    // </ul>
    // Example:
    // <pre><code>t2s_config_service={&apos;aws_access_key_id&apos;: &apos;YOUR_AWS_ACCESS_KEY_ID&apos;, &apos;aws_secret_access_key&apos;: &apos;YOUR_AWS_SECRET_ACCESS_KEY&apos;, &apos;region&apos;: &apos;YOUR_AMAZON_SERVER_REGION_NAME&apos;}</code></pre>
    //
    // B. For ElevenLabs T2s service, the following arguments should be passed:
    // <ul>
    //   <li>B1. <code>api_key</code> (required) API key of ElevenLabs cloud provider to access its T2S service.</li>
    // </ul>
    // Example:
    // <pre><code>t2s_config_service={&apos;api_key&apos;: &apos;YOUR_ELEVENLABS_API_KEY&apos;}</code></pre>
    //
    // C. For Google cloud T2S service, the following arguments should be passed:
    // <ul>
    //   <li>C1. <code>api_key</code> (required) API key of Google cloud provider to access its T2S service.</li>
    //   <li>C2. <code>api_endpoint</code> (optional) Regional API endpoint of Google cloud T2S service.
    //     (Defaults to &apos;eu-texttospeech.googleapis.com&apos;)</li>
    // </ul>
    // Example:
    // <pre><code>t2s_config_service={&apos;api_key&apos;: &apos;YOUR_GOOGLE_CLOUD_API_KEY&apos;, &apos;api_endpoint&apos;: &apos;YOUR_GOOGLE_CLOUD_API_ENDPOINT&apos;}</code></pre>
    //
    // D. For Microsoft Azure T2s service, the following arguments should be passed:
    // <ul>
    //   <li>D1. <code>subscription_key</code> (required) Subscription key to access Microsoft Azure Service.</li>
    //   <li>D2. <code>region</code> (required) Region name of Microsoft Azure Server.</li>
    // </ul>
    // Example:
    // <pre><code>t2s_config_service={&apos;subscription_key&apos;: &apos;YOUR_MICROSOFT_AZURE_SUBSCRIPTION_KEY&apos;, &apos;region&apos;: &apos;YOUR_MICROSOFT_AZURE_SERVER_REGION_NAME&apos;}</code></pre>
    //
    // Note: ondewo-t2s will raise an error if you don&apos;t pass any of the required arguments above.
    optional google.protobuf.Struct t2s_service_config = 9;

    // Optional. Defines the cloud provider's specific configuration for using text to speech cloud services
    // The default value is None.
    optional T2sCloudProviderConfig t2s_cloud_provider_config = 10;

    oneof oneof_t2s_normalization {
        // Optional. Define t2s_normalization config parameters for this specific request.
        // The default values are set in the config file and the values set via RequestConfig are set just for
        // this specific request and will not update the pipeline.
        T2SNormalization t2s_normalization = 11;
    }

    // Optional. Define a dict which specifies the phonemes for a special word.
    optional google.protobuf.Struct word_to_phoneme_mapping = 12;

}

// <p>Configuration for cloud provider settings for Text-to-Speech (T2S).</p>
message T2sCloudProviderConfig {

    // Configuration for Eleven Labs text-to-speech provider.
    T2sCloudProviderConfigElevenLabs t2s_cloud_provider_config_elevenlabs = 1;

    // Configuration for Google text-to-speech provider.
    T2sCloudProviderConfigGoogle t2s_cloud_provider_config_google = 2;

    // Configuration for Microsoft text-to-speech provider.
    T2sCloudProviderConfigMicrosoft t2s_cloud_provider_config_microsoft = 3;

}

// <p>Configuration details specific to the Eleven Labs text-to-speech provider.</p>
message T2sCloudProviderConfigElevenLabs {

    // Stability level for inference, influencing consistency of generated speech. It is in the range [0.0, 1.0].
    float stability = 1;

    // Boost value for similarity to enhance the similarity of the generated voice to a target voice.
    // It is in the range [0.0, 1.0].
    float similarity_boost = 2;

    // Style parameter to control the expression or emotion in speech. It is in the range [0.0, 1.0].
    float style = 3;

    // Enables or disables speaker boost for emphasis on clarity and loudness.
    bool use_speaker_boost = 4;

    // Specifies type of text normalization to apply during processing. Available options are 'auto', 'on', and 'off'.
    string apply_text_normalization = 5;

}

// <p>Configuration details specific to the Microsoft text-to-speech provider.</p>
message T2sCloudProviderConfigMicrosoft {

    // Determines whether to use the default speaker voice.
    bool use_default_speaker = 1;

}

// <p>Configuration details specific to the Google text-to-speech provider.</p>
message T2sCloudProviderConfigGoogle {

    // Speaking rate for inference, controlling the speed of generated speech. It is in the range [0.25, 4.0].
    float speaking_rate = 1;

    // Volume gain in dB applied to the generated speech. It is in the range [-96.0, 16.0].
    float volume_gain_db = 2;

    // Pitch adjustment for inference, allowing control over voice pitch. It is in the range in the range [-20.0, 20.0].
    float pitch = 3;

}

// <p>Represents a pulse-code modulation technique.</p>
enum Pcm {

    // 16-bit pulse-code modulation.
    PCM_16 = 0;

    // 24-bit pulse-code modulation.
    PCM_24 = 1;

    // 32-bit pulse-code modulation.
    PCM_32 = 2;

    // Signed 8-bit pulse-code modulation.
    PCM_S8 = 3;

    // Unsigned 8-bit pulse-code modulation.
    PCM_U8 = 4;

    // Floating-point (32-bit) pulse-code modulation.
    FLOAT = 5;

    // Floating-point (64-bit) pulse-code modulation.
    DOUBLE = 6;
}

// <p>AudioFormat enum represents various audio file formats for storing digital audio data.</p>
enum AudioFormat {

    // Waveform Audio File Format (WAV)
    wav = 0;

    // Free Lossless Audio Codec (FLAC)
    flac = 1;

    // Core Audio Format (CAF)
    caf = 2;

    // MPEG Audio Layer III (MP3)
    mp3 = 3;

    // Advanced Audio Coding (AAC)
    aac = 4;

    // Ogg Vorbis (OGG)
    ogg = 5;

    // Windows Media Audio (WMA)
    wma = 6;

}

// <p>Represents a Synthesize Response.</p>
// <p>A Synthesize Response contains the generated audio, requested text and all other properties of this generated audio.</p>
message SynthesizeResponse {

    // Required. Represents the pipeline id of the model configuration that will be used.
    string audio_uuid = 1;

    // Required. Generated file with the parameters described in request.
    bytes audio = 2;

    // Required. Time to generate audio.
    float generation_time = 3;

    // Required. Audio length.
    float audio_length = 4;

    // Required. Text from which audio was generated.
    string text = 5;

    // Required. Configuration from which audio was generated.
    RequestConfig config = 6;

    // Optional. Normalized text.
    string normalized_text = 7;

    // Optional. Value of sampling rate
    float sample_rate = 8;

}

// <p>Represents a Streaming Synthesize Response.</p>
// <p>A Streaming Synthesize Response contains the generated audio, requested text and and
// all other properties of this generated audio.</p>
message StreamingSynthesizeResponse {

    // Required. Represents the pipeline id of the model configuration that will be used.
    string audio_uuid = 1;

    // Required. Generated file with the parameters described in request.
    bytes audio = 2;

    // Required. Time to generate audio.
    float generation_time = 3;

    // Required. Audio length.
    float audio_length = 4;

    // Required. Text from which audio was generated.
    string text = 5;

    // Required. Configuration from which audio was generated.
    RequestConfig config = 6;

    // Optional. Normalized text.
    string normalized_text = 7;

    // Optional. Value of sampling rate
    float sample_rate = 8;

}

///////////////
// NORMALIZE //
///////////////

// <p>NormalizeTextRequest message is used to request text normalization.</p>
message NormalizeTextRequest {

    // The ID of the text-to-speech pipeline.
    string t2s_pipeline_id = 1;

    // The text to be normalized.
    string text = 2;

}

// <p>NormalizeTextResponse message is used to store the normalized text response.</p>
message NormalizeTextResponse {

    // The normalized text.
    string normalized_text = 1;

}

//////////////////////
// GET SERVICE INFO //
//////////////////////

// <p>Version information of the service</p>
message T2SGetServiceInfoResponse {

    // version number
    string version = 1;
}

////////////////////////
// LIST T2S PIPELINES //
////////////////////////

// <p>Pipeline Request representation.</p>
// <p>The request message for ListT2sPipelines.</p>
// <p>Filter pipelines by attributed in request.</p>
message ListT2sPipelinesRequest {

    // Optional. Define the language/ languages.
    repeated string languages = 1;

    // Optional. Define the speaker sex.
    repeated string speaker_sexes = 2;

    // Optional. Define the pipeline owner/ owners.
    repeated string pipeline_owners = 3;

    // Optional. Define the speaker name/ names.
    repeated string speaker_names = 4;

    // Optional. Define the domain/ domains.
    repeated string domains = 5;

}

// <p>Pipeline Response representation.</p>
// <p>The response message for ListT2sPipelines.</p>
message ListT2sPipelinesResponse {

    // Required. Representation of a list of pipelines configurations.
    // Retrieved by ListT2sPipelines, containing the configurations of
    // pipelines with the specifications received in the ListT2sPipelinesRequest.
    repeated Text2SpeechConfig pipelines = 1;

}

////////////////////////
// LIST T2S LANGUAGES //
////////////////////////


// <p>Language Request representation.</p>
// <p>The request message for ListT2sLanguages.</p>
// <p>Filter languages of pipelines by attributed in request.</p>
message ListT2sLanguagesRequest {

    // Optional. Define the speaker sex.
    repeated string speaker_sexes = 1;

    // Optional. Define the pipeline owner/ owners.
    repeated string pipeline_owners = 2;

    // Optional. Define the speaker name/ names.
    repeated string speaker_names = 3;

    // Optional. Define the domain/ domains.
    repeated string domains = 4;

}


// <p>Language Response representation.</p>
// <p>The response message for ListT2sLanguages.</p>
message ListT2sLanguagesResponse {

    // Required. Define the language/ languages that satisfy/ies
    // the specifications in the ListT2sLanguagesRequest.
    repeated string languages = 1;

}

//////////////////////
// LIST T2S DOMAINS //
//////////////////////


// <p>Domain Request representation.</p>
// <p>The request message for ListT2sDomains.</p>
// <p>Filter domains of pipelines by attributed in request.</p>
message ListT2sDomainsRequest {

    // Optional. Define the speaker sex.
    repeated string speaker_sexes = 1;

    // Optional. Define the pipeline owner/ owners.
    repeated string pipeline_owners = 2;

    // Optional. Define the speaker name/ names.
    repeated string speaker_names = 3;

    // Optional. Define the language/ languages.
    repeated string languages = 4;

}

// <p>Domains Response representation.</p>
// <p>The response message for ListT2sDomains.</p>
message ListT2sDomainsResponse {

    // Required. Define the domain/ domains that satisfy/ies
    // the specifications in the ListT2sDomainsRequest.
    repeated string domains = 1;

}

////////////////////////
// LIST T2S NORMALIZATION PIPELINES //
////////////////////////

// <p>The request message for ListT2sNormalizationPipelines.</p>
// <p>Filter pipelines by attributed in request.</p>
message ListT2sNormalizationPipelinesRequest {

    // Optional. Define the language.
    string language = 1;

}

// <p>Pipeline Response representation.</p>
// <p>The response message for ListT2sNormalizationPipelines.</p>
message ListT2sNormalizationPipelinesResponse {

    // Required. Representation of a list of normalization pipelines configurations.
    // Retrieved by ListT2sNormalizationPipelines, containing the configurations of
    // normalization pipelines with the specifications received in the ListT2sNormalizationPipelinesRequest.
    repeated string t2s_normalization_pipelines = 1;

}

/////////////////////////
// UPDATE T2S PIPELINE //
/////////////////////////


// <p>Pipeline Id representation.</p>
// <p>Used in the creation, deletion and getter of pipelines.</p>
message T2sPipelineId {

    // Required. Defines the id of the pipeline.
    string id = 1;

}

///////////////////////////
// Text-to-Speech Config //
///////////////////////////

// <p>Configuration of text-to-speech models representation.</p>
message Text2SpeechConfig {

    // Required. Defines the id of the pipeline.
    string id = 1;

    // Required. Defines the description of the pipeline representation.
    T2SDescription description = 2;

    // Required. Defines if the pipeline is active or inactive.
    bool active = 3;

    // Required. Defines he inference of the pipeline representation.
    T2SInference inference = 4;

    // Required. Defines the normalization process of the pipeline representation.
    T2SNormalization normalization = 5;

    // Required. Defines the postprocessing process of the pipeline representation.
    Postprocessing postprocessing = 6;

}


// <p>T2SDescription message is used to describe the text-to-speech service.</p>
message T2SDescription {

    // The language supported by the service.
    string language = 1;

    // The speaker's sex or gender.

    string speaker_sex = 2;

    // The owner of the text-to-speech pipeline.
    string pipeline_owner = 3;

    // Additional comments or notes.
    string comments = 4;

    // The name of the speaker.
    string speaker_name = 5;

    // The domain or context of the service.
    string domain = 6;

}

// <p>T2SInference message is used to specify the text-to-speech inference settings.</p>
message T2SInference {

    // The type of inference.
    string type = 1;

    // Composite inference settings.
    CompositeInference composite_inference = 2;

    // Single inference settings.
    SingleInference single_inference = 3;

    // Caching settings.
    Caching caching = 4;
}

// <p>CompositeInference message combines text-to-mel and mel-to-audio inference settings.</p>
message CompositeInference {

    // Text-to-mel inference settings.
    Text2Mel text2mel = 1;

    // Mel-to-audio inference settings.
    Mel2Audio mel2audio = 2;

}

// <p>SingleInference message inference settings of text2audio models.</p>
message SingleInference {

    // Text-to-audio inference settings.
    Text2Audio text2audio = 1;

}

// <p>Text2Mel message contains settings for text-to-mel inference.</p>
message Text2Mel {

    // The type of text-to-mel inference.
    string type = 1;

    // GlowTTS inference settings.
    GlowTTS glow_tts = 2;

    // GlowTTS Triton inference settings.
    GlowTTSTriton glow_tts_triton = 3;

}

// <p>Text2Audio message contains settings for text-to-audio inference.</p>
message Text2Audio {

    // The type of text-to-audio inference.
    string type = 1;

    // Vits inference settings.
    Vits vits = 2;

    // Vits Triton inference settings.
    VitsTriton vits_triton = 3;

    // ElevenLabs cloud service inference settings.
    T2sCloudServiceElevenLabs t2s_cloud_service_elevenlabs = 4;

    // Amazon cloud service inference settings.
    T2sCloudServiceAmazon t2s_cloud_service_amazon = 5;

    // Google cloud service inference settings.
    T2sCloudServiceGoogle t2s_cloud_service_google = 6;

    // Microsoft cloud service inference settings.
    T2sCloudServiceMicrosoft t2s_cloud_service_microsoft = 7;

}

// <p>GlowTTS message contains settings for the GlowTTS inference.</p>
message GlowTTS {

    // The batch size for inference.
    int64 batch_size = 1;

    // Flag indicating whether to use GPU for inference.
    bool use_gpu = 2;

    // The length scale for inference.
    float length_scale = 3;

    // The noise scale for inference.
    float noise_scale = 4;

    // The path to the GlowTTS model.
    string path = 5;

    // Repeated field containing the cleaners for text normalization.
    repeated string cleaners = 6;

    // The path to the parameter configuration.
    string param_config_path = 7;

}

// <p>GlowTTSTriton message contains settings for the GlowTTS Triton inference.</p>
message GlowTTSTriton {

    // The batch size for inference.
    int64 batch_size = 1;

    // The length scale for inference.
    float length_scale = 2;

    // The noise scale for inference.
    float noise_scale = 3;

    // Repeated field containing the cleaners for text normalization.
    repeated string cleaners = 4;

    // The maximum text length allowed.
    int64 max_text_length = 5;

    // The path to the parameter configuration.
    string param_config_path = 6;

    // The name of the Triton model.
    string triton_model_name = 7;

    // The host of the Triton inference server which servers the model.
    string triton_server_host = 8;

    // The port of the Triton inference server which servers the model.
    int64 triton_server_port = 9;

}

// <p>Vits message contains settings for the Vits inference.</p>
message Vits {

    // The batch size for inference.
    int64 batch_size = 1;

    // Flag indicating whether to use GPU for inference.
    bool use_gpu = 2;

    // The length scale for inference.
    float length_scale = 3;

    // The noise scale for inference.
    float noise_scale = 4;

    // The path to the Vits model.
    string path = 5;

    // Repeated field containing the cleaners for text normalization.
    repeated string cleaners = 6;

    // The path to the parameter configuration.
    string param_config_path = 7;

}

// <p>VitsTriton message contains settings for the Vits Triton inference.</p>
message VitsTriton {

    // The batch size for inference.
    int64 batch_size = 1;

    // The length scale for inference.
    float length_scale = 2;

    // The noise scale for inference.
    float noise_scale = 3;

    // Repeated field containing the cleaners for text normalization.
    repeated string cleaners = 4;

    // The maximum text length allowed.
    int64 max_text_length = 5;

    // The path to the parameter configuration.
    string param_config_path = 6;

    // The name of the Triton model.
    string triton_model_name = 7;

    // The host of the Triton inference server which servers the model.
    string triton_server_host = 8;

    // The port of the Triton inference server which servers the model.
    int64 triton_server_port = 9;

}

// <p>T2sCloudServiceElevenLabs message contains settings for the ElevenLabs Cloud service inference.</p>
message T2sCloudServiceElevenLabs {

    // Language of the generated audio. It should be 4-Letter language code.
    string language_code = 1;

    // Model ID indicating the name of the model
    string model_id = 2;

    // Voice ID indicating the speaker
    string voice_id = 3;

    // Voice setting of the inference
    VoiceSettings voice_settings = 4;

    // Flag to indicate applying text normalization
    string apply_text_normalization = 5;

}

// <p>VoiceSettings message contains settings for ElevenLabs inference.</p>
message VoiceSettings{

    // stability value for elevenlabs inference
    float stability = 1;

    // similarity boost value for ElevenLabs inference.
    float similarity_boost = 2;

    // style boost value for ElevenLabs inference.
    float style = 3;

    // Flag to indicate speaker boost
    bool use_speaker_boost = 4;
}

// <p>T2sCloudServiceAmazon message contains settings for the Amazon Cloud service inference.</p>
message T2sCloudServiceAmazon {

    // Voice ID indicating the speaker
    string voice_id = 1;

    // Model id for the inference server.
    string model_id = 2;

}

// <p>T2sCloudServiceGoogle message contains settings for the Google Cloud service inference.</p>
message T2sCloudServiceGoogle {

    // Voice ID indicating the speaker
    string voice_id = 1;

    // Speaking rate to control the speed of audio.
    float speaking_rate = 2;

    // Volume gain in db to control volume of the audio.
    float volume_gain_db = 3;

    // pitch value of the audio
    float pitch = 4;

}

// <p>T2sCloudServiceMicrosoft message contains settings for the Microsoft Cloud service inference.</p>
message T2sCloudServiceMicrosoft {

    // Voice ID indicating the speaker.
    string voice_id = 1;

    // Flag to indicate using the default speaker.
    bool use_default_speaker = 2;

}

// <p>Mel2Audio message contains settings for mel-to-audio inference.</p>
message Mel2Audio {

    // The type of mel-to-audio inference.
    string type = 1;

    // MbMelgan Triton inference settings.
    MbMelganTriton mb_melgan_triton = 2;

    // HiFiGan inference settings.
    HiFiGan hifi_gan = 3;

    // HiFiGan Triton inference settings.
    HiFiGanTriton hifi_gan_triton = 4;

}

// <p>HiFiGan message contains settings for the HiFiGan inference.</p>
message HiFiGan {

    // Flag indicating whether to use GPU for inference.
    bool use_gpu = 1;

    // The batch size for inference.
    int64 batch_size = 2;

    // The path to the HiFiGan configuration.
    string config_path = 3;

    // The path to the HiFiGan model.
    string model_path = 4;

}

// <p>HiFiGanTriton message contains settings for the HiFiGan Triton inference.</p>
message HiFiGanTriton {

    // The path to the HiFiGan Triton configuration.
    string config_path = 1;

    // The name of the Triton model.
    string triton_model_name = 2;

    // The host of the Triton inference server which servers the model.
    string triton_server_host = 3;

    // The port of the Triton inference server which servers the model.
    int64 triton_server_port = 4;

}

// <p>MbMelganTriton message contains settings for the MbMelgan Triton inference.</p>
message MbMelganTriton {

    // The path to the MbMelgan Triton configuration.
    string config_path = 1;

    // The path to the MbMelgan statistics.
    string stats_path = 2;

    // The name of the Triton model.
    string triton_model_name = 3;

    // The host of the Triton inference server which servers the model.
    string triton_server_host = 4;

    // The port of the Triton inference server which servers the model.
    int64 triton_server_port = 5;

}

// <p>Caching message contains settings for caching.</p>
message Caching {

    // Flag indicating whether caching is active.
    bool active = 1;

    // The maximum size of the memory cache.
    int64 memory_cache_max_size = 2;

    // The sampling rate for caching.
    int64 sampling_rate = 3;

    // Flag indicating whether to load cache.
    bool load_cache = 4;

    // Flag indicating whether to save cache.
    bool save_cache = 5;

    // The directory path to save the cache.
    string cache_save_dir = 6;

}
// <p>Represents the configuration for text-to-speech normalization.</p>
message T2SNormalization {

    // The language for which the normalization is applied.
    string language = 1;

    // The pipeline(s) used for normalization.
    repeated string pipeline = 2;

    // The ID of the custom phonemizer, if used.
    string custom_phonemizer_id = 3;

    // Custom length scales for different text types.
    T2SCustomLengthScales custom_length_scales = 4;

    // The mapping for Arpabet phonemes.
    string arpabet_mapping = 5;

    // The mapping for numeric expressions.
    string numeric_mapping = 6;

    // The mapping for callsigns.
    string callsigns_mapping = 7;

    // The mapping for phoneme correction.
    string phoneme_correction_mapping = 8;

}

// <p>Postprocessing message contains settings for postprocessing.</p>
message Postprocessing {

    // The duration of silence in seconds.
    float silence_secs = 1;

    // Repeated field containing pipeline names.
    repeated string pipeline = 2;

    // Logmnse postprocessing settings.
    Logmnse logmmse = 3;

    // Wiener postprocessing settings.
    Wiener wiener = 4;

    // Apodization postprocessing settings.
    Apodization apodization = 5;

}

// <p>Logmnse message contains settings for Logmnse postprocessing.</p>
message Logmnse {

    // The initial noise value.
    int64 initial_noise = 1;

    // The window size.
    int64 window_size = 2;

    // The noise threshold.
    float noise_threshold = 3;

}

// <p>Wiener message contains settings for Wiener postprocessing.</p>
message Wiener {

    // The frame length.
    int64 frame_len = 1;

    // The LPC order.
    int64 lpc_order = 2;

    // The number of iterations.
    int64 iterations = 3;

    // The alpha value.
    float alpha = 4;

    // The threshold value.
    float thresh = 5;

}

// <p>Apodization message contains settings for apodization postprocessing.</p>
message Apodization {

    // The duration of apodization in seconds.
    float apodization_secs = 1;

}

// <p>T2SCustomLengthScales message contains custom length scales for text types.</p>
message T2SCustomLengthScales {

    // The custom length scale for general text.
    float text = 1;

    // The custom length scale for email text.
    float email = 2;

    // The custom length scale for URL text.
    float url = 3;

    // The custom length scale for phone number text.
    float phone = 4;

    // The custom length scale for spelled-out text.
    float spell = 5;

    // The custom length scale for spelled-out text with names.
    float spell_with_names = 6;

    // The custom length scale for long callsigns.
    float callsign_long = 7;

    // The custom length scale for short callsigns.
    float callsign_short = 8;

}


// <p>PhonemizerId message represents the ID of a phonemizer.</p>
message PhonemizerId {

    // The ID of the phonemizer.
    string id = 1;

}

// <p>CustomPhonemizerProto message represents a custom phonemizer.</p>
message CustomPhonemizerProto {

    // The ID of the custom phonemizer.
    string id = 1;

    // Repeated field of Map messages representing word-to-phoneme mappings.
    repeated Map maps = 2;
}

// <p>Map message represents a word-to-phoneme mapping in a custom phonemizer.</p>
message Map {

    // The word to be mapped.
    string word = 1;

    // The phoneme groups associated with the word.
    string phoneme_groups = 2;

}

// <p>ListCustomPhonemizerResponse message represents the response for listing custom phonemizers.</p>
message ListCustomPhonemizerResponse {

    // Repeated field of CustomPhonemizerProto messages representing the custom phonemizers.
    repeated CustomPhonemizerProto phonemizers = 1;

}

// <p>ListCustomPhonemizerRequest message represents the request for listing custom phonemizers.</p>
message ListCustomPhonemizerRequest {

    // Repeated field of pipeline IDs to filter the list of custom phonemizers.
    repeated string pipeline_ids = 1;

}

// <p>UpdateCustomPhonemizerRequest message represents the request for updating a custom phonemizer.</p>
message UpdateCustomPhonemizerRequest {

    // The ID of the custom phonemizer to be updated.
    string id = 1;

    // The update method to be used.
    enum UpdateMethod {

        // Add new words, replacing existing ones.
        extend_hard = 0;

        // Add new words if they are not already present.
        extend_soft = 1;

        // Replace all words in the phonemizer with new ones.
        replace = 2;

    }

    // The update method.
    UpdateMethod update_method = 2;

    // Repeated field of Map messages representing word-to-phoneme mappings.
    repeated Map maps = 3;
}

// <p>CreateCustomPhonemizerRequest message represents the request for creating a custom phonemizer.</p>
message CreateCustomPhonemizerRequest {

    // The prefix for the custom phonemizer ID.
    string prefix = 1;

    // Repeated field of Map messages representing word-to-phoneme mappings.
    repeated Map maps = 2;

}
