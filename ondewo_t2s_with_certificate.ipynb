{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKWBIVdK_r0Z"
   },
   "source": [
    "## **Text2Speech T2S API**\n",
    "\n",
    "This tutorial uses ondewo-t2s-api to:\n",
    "\n",
    "*   List the possible pipelines that can be used for synthesizing\n",
    "*   List the possible languages that can be used in the synthesize process\n",
    "*   List the possible domains\n",
    "*   Synthesize a text to audio\n",
    "*   Synthesize a batch of texts to audios\n",
    "*   Manipulate pipelines (Create, Delete, Update, Get)\n",
    "\n",
    "\n",
    "The first step is to install and the Ondewo Text to Speech client and the requirements needed to interact with the server\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2ePqjpJccmr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "! pwd\n",
    "! ls\n",
    "! rm -rf ondewo-t2s-client-python\n",
    "! git clone https://github.com/ondewo/ondewo-t2s-client-python.git\n",
    "! cd ondewo-t2s-client-python && git checkout tags/3.1.1 -b 3.1.2 && pip install -r requirements.txt  && git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AZCHNpJytnZ"
   },
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "! cd ondewo-t2s-client-python && python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u05mpboMICjZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "import grpc\n",
    "from ondewo.t2s import text_to_speech_pb2, text_to_speech_pb2_grpc\n",
    "from google.protobuf.json_format import ParseDict, MessageToDict, MessageToJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqzktvBHdNHN"
   },
   "source": [
    "Afterwards, the client's objects classes need to be imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_l5Y2hqdLO1"
   },
   "outputs": [],
   "source": [
    "from ondewo.t2s import text_to_speech_pb2\n",
    "from ondewo.t2s.client.client import Client\n",
    "from ondewo.t2s.client.client_config import ClientConfig\n",
    "from ondewo.t2s.client.services.text_to_speech import Text2Speech\n",
    "from ondewo.t2s.text_to_speech_pb2 import ListT2sPipelinesRequest, Text2SpeechConfig \n",
    "from ondewo.t2s.text_to_speech_pb2 import ListT2sLanguagesRequest, ListT2sDomainsRequest\n",
    "from ondewo.t2s.text_to_speech_pb2 import T2sPipelineId, RequestConfig, SynthesizeRequest\n",
    "from ondewo.t2s.text_to_speech_pb2 import BatchSynthesizeRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg990OWCtZRw"
   },
   "source": [
    "## Connect to the Text to Speech Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9Dsp0u7JE-y"
   },
   "source": [
    "The example below shows how to create a secure channel for a text to speech stub object. When setting *use_secure_channel=True*, a grpc certificate *grpc_cert* is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQ4eTNYLJY0W"
   },
   "outputs": [],
   "source": [
    "#credentials = grpc.ssl_channel_credentials(root_certificates=cert)\n",
    "\n",
    "MAX_MESSAGE_LENGTH: int = 60000000\n",
    "GRPC_HOST: str = \"localhost\"\n",
    "GRPC_PORT: str = \"50555\"\n",
    "CHANNEL: str = f\"{GRPC_HOST}:{GRPC_PORT}\"\n",
    "cert=None\n",
    "\n",
    "\n",
    "options = [\n",
    "    ('grpc.max_send_message_length', MAX_MESSAGE_LENGTH),\n",
    "    ('grpc.max_receive_message_length', MAX_MESSAGE_LENGTH),\n",
    "]\n",
    "\n",
    "#channel = grpc.secure_channel(CHANNEL, credentials, options=options)\n",
    "\n",
    "config: ClientConfig = ClientConfig(\n",
    "  host=GRPC_HOST,\n",
    "  port=GRPC_PORT, \n",
    "  grpc_cert=cert)\n",
    "    \n",
    "print(config)\n",
    "    \n",
    "client: Client = Client(config=config, use_secure_channel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNqz0BBntZRy"
   },
   "source": [
    "## Get the service information\n",
    "In order to get the service information, the following method can be executed. This last will retrieve the release version of the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJwo2mjbtZR0"
   },
   "outputs": [],
   "source": [
    "client.services.text_to_speech.get_service_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD27LELbJjxg"
   },
   "source": [
    "## List all existing text to speech pipelines\n",
    "\n",
    "All relevant configurations of the text to speech server are defined in a text to speech pipeline. A running server can store several of such configurations at the same time, and the client can chose which one to pick when he/she sends a request to synthesize a text or batch of texts.\n",
    "\n",
    "The example below shows how to list all available pipelines by calling the *ListT2sPipelines* function, which takes a *ListT2sPipelinesRequest* as an argument and retrieves a *ListT2sPipelinesResponse*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkgvlYO7JmX_"
   },
   "outputs": [],
   "source": [
    "pipelines = client.services.text_to_speech.list_t2s_pipelines(request=ListT2sPipelinesRequest())\n",
    "pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhaYY8x6s18d"
   },
   "source": [
    "## List all possible synthesizying languages\n",
    "\n",
    "A running server can list all possible languages fulfilling specified requirements that can be used to synthesize.\n",
    "\n",
    "The example below shows how to list all available languages by calling the *ListT2sLanguages* function, which takes a *ListT2sLanguagesRequest* as an argument and retrieves a *ListT2sLanguagesResponse*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lN6L5LhitleH"
   },
   "outputs": [],
   "source": [
    "request = ListT2sLanguagesRequest(speaker_sexes=['female'])\n",
    "response = client.services.text_to_speech.list_t2s_languages(request=request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk7s6tNvusda"
   },
   "source": [
    "## List all possible domains\n",
    "\n",
    "A running server can list all possible domains fulfilling specified requirements that can be used to synthesize.\n",
    "\n",
    "The example below shows how to list all available domains by calling the *ListT2sDomains* function, which takes a *ListT2sDomainsRequest* as an argument and retrieves a *ListT2sDomainsResponse*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAv4fX5-vIkl"
   },
   "outputs": [],
   "source": [
    "request = ListT2sDomainsRequest(languages=['en'])\n",
    "response = client.services.text_to_speech.list_t2s_domains(request=request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kcutwJDLTs-"
   },
   "source": [
    "# Make a synthesize request to the server\n",
    "\n",
    "The running server offers a feature for synthesizying a text into a audio. In order to make use of it, the Synthesize method is utilized. This method will receive a SynthesizeRequest and retrieve a SynthesizeResponse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVdvO-oxUAAR"
   },
   "source": [
    "The following pipelines were chosen to examplify.\n",
    "Brigitte's voice is choosen for the english voice and Brigitte's voice for german. Therefore, both pipelines need to be asked for to the stab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9V7vPlstZR5"
   },
   "outputs": [],
   "source": [
    "english_pipeline = T2sPipelineId(id='brigitte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWn5NWOcUBLi"
   },
   "outputs": [],
   "source": [
    "german_pipeline = T2sPipelineId(id='brigitte_de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yENiOXlfUSpg"
   },
   "source": [
    "The example below shows how to synthesize a text into an audio.\n",
    "1.   A configuration has to be created with a *RequestConfig*, specifying the desired optional parameters.\n",
    "2.   A request has to be created with a *SynthesizeRequest*, specifying the text to be synthesize and the previously created configuration.\n",
    "3.   By calling the Synthesize method with the created request, the text is synthesized with the specfified configuration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gm_phM3atZR6"
   },
   "source": [
    "The following example was created with Brigitte's voice, so as to get an english speaker pronunciation in the audio for the text synthesized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTEIIv8qtZR6"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, \n",
    "                       length_scale = 1.0)\n",
    "request = SynthesizeRequest(text=\"Hi, this is Brigitte. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\", \n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpL5lStDtZR7"
   },
   "source": [
    "### Length scale configuration\n",
    "The attribute length_scale can be finetuned in order to speed up or slow down the audio. \n",
    "In the next example the length_scale attribute is set to 0.5 so the retrieved audio will be twice as fast as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jMXjjb3tZR7"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, \n",
    "                       length_scale = 0.5)\n",
    "request = SynthesizeRequest(text=\"Hi, this is Brigitte. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk8HTDMRtZR7"
   },
   "source": [
    "Next, the same attribute is being set to 2.0, therefore, the retrieved audio will be half as fast in comparison to the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UrYguj_L3dx"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, \n",
    "                       length_scale = 2.0)\n",
    "request = SynthesizeRequest(text=\"Hi, this is Brigitte. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_015ySStZR8"
   },
   "source": [
    "### Audio Format confguration\n",
    "\n",
    "Another attribute that can be configurated is the audio_format.\n",
    "Audio Format can the setted to:\n",
    "\n",
    "- 0 for wav\n",
    "- 1 for flac\n",
    "- 2 for caf (Core audio format)\n",
    "- 3 for mp3\n",
    "- 4 for acc (Advanced audio coding)\n",
    "- 5 for ogg\n",
    "- 6 for wma (Windows media audio)\n",
    "\n",
    "In the following example, the attribute audio_format is setted to create a wav audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gquB0QY8tZR8"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, \n",
    "                       audio_format = 0)\n",
    "request = SynthesizeRequest(text=\"Hi, this is Brigitte. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "psU228XMtZR8"
   },
   "source": [
    "### Pulse Code Modulation\n",
    "\n",
    "The pcm attribute represents the number of pulses created for the audio file.\n",
    "A pcm signal is a sequence of digital audio samples containing the data providing the necessary information to reconstruct the original analog signal.\n",
    "\n",
    "- 0 for 16 (16  bits per sample)\n",
    "- 1 for 24 (24  bits per sample)\n",
    "- 2 for 32 (32  bits per sample)\n",
    "- 3 for S8\n",
    "- 4 for U8\n",
    "- 5 for Float\n",
    "- 6 for Double\n",
    "\n",
    "The number of bit per sample affects the quality and size of the retrieved file. As the number of bits per sample increase, so does the size and quality of the file.\n",
    "\n",
    "In the first example the audio file is generated with the best possible quality and in the second, with the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DvuWz35tZR8"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, pcm = 0)\n",
    "request = SynthesizeRequest(text=\"Hi, this is Brigitte. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtdyG5oitZR9"
   },
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id, pcm = 4)\n",
    "request = SynthesizeRequest(text=\"Hi, this is Brigitte. Thanks for calling. I'm not here at the moment, so please leave a message and I'll call you back.\",\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSML Tags\n",
    "\n",
    "When the servie returns a response to a user's request, the user provides text that the Ondewo text-to-speech service converts to speech. Ondewo's voices automatically handles normal punctuation, such as pausing after a period.\n",
    "\n",
    "However, in some cases you may want additional control over how the chosen voice generates the speech from the text in your response. For example, you may want the text to be spelled as a code or id, or you may want a string of digits read back as a standard telephone number, email or url. The SSML Tag incorporation provides this type of control over the synthesying process.\n",
    "\n",
    "SSML is a markup language that provides a standard way to mark up text for the generation of synthetic speech. Ondewo's voices supports a subset of the tags defined in the SSML specification. The specific tags supported are: email, phone, urls, spell and spell-with-names.\n",
    "\n",
    "See how SSML works: https://docs.aws.amazon.com/polly/latest/dg/ssml.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSML Phone Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(text='Hi, this is Brigitte. Thanks for calling. I am not here at the moment, so please leave a message to the following number <say-as interpret-as=\"phone\">+12354321</say-as>and I will call you back.',\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSML Email Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(text='Hi, this is Brigitte. Thanks for calling. I am not here at the moment, so please send an email to the following address <say-as interpret-as=\"email\">voices@ondewo.com.at</say-as>',\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSML Url Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(text='Hi, this is Brigitte. Thanks for calling. I am not here at the moment, so please visit the site <say-as interpret-as=\"url\">https://ondewo.com/en/</say-as>',\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSML Spell Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(text='My reservation number is <say-as interpret-as=\"spell\">ABC123DEF!</say-as>',\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSML Spell With Names Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(text='My reservation number is <say-as interpret-as=\"spell-with-names\">ABC123DEF!</say-as>',\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arphabet Phonemes\n",
    "\n",
    "Most languages, including English, can be described in terms of a set of distinctive sounds, or phonemes. In particular, for American English, there are about 42 phonemes including vowels, diphthongs, semi-vowels and consonants. \n",
    "\n",
    "The internationally standard method to represent phonemes is International Phonetic Alphabet (IPA). To enable computer representation of the phonemes, it is convenient to code them as ASCII characters and we can do this with the ARPABET scheme.\n",
    "\n",
    "For example:\n",
    "\n",
    "- Bee : {B IY1}\n",
    "- She : {SH IY1}\n",
    "- Red : {R EH1 D}\n",
    "- Sofa : {S OW1 F AH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RequestConfig(t2s_pipeline_id=english_pipeline.id)\n",
    "request = SynthesizeRequest(text='Hello I am {AE2 L EH0 G Z AE1 N D R AH0}',\n",
    "                            config=config)\n",
    "response = client.services.text_to_speech.synthesize(request=request)\n",
    "display(Audio(response.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdfCmhBSAGOm"
   },
   "source": [
    "# Make a synthesize request to the server for a batch of texts\n",
    "\n",
    "The running server offers a feature for synthesizying a batch of texts into audios. In order to make use of it, the BatchSynthesize method is utilized. This method will receive a BatchSynthesizeRequest and retrieve a BatchSynthesizeResponse.\n",
    "\n",
    "The example below shows how to synthesize a batch of texts into a audios.\n",
    "\n",
    "1.   A configuration has to be created with a RequestConfig, specifying the desired optional parameters for each text in the batch.\n",
    "2.   A request has to be created with a SynthesizeRequest, specifying the text to be synthesize and the previously created configuration for each text in the batch with its desired configuration.\n",
    "3.  By calling the BatchSynthesize with the created request, the text is synthesized with the specfified configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3erqBYpALJ9"
   },
   "source": [
    "The following pipelines were chosen to examplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5B1wLqTAUuu"
   },
   "outputs": [],
   "source": [
    "config_1 = RequestConfig(t2s_pipeline_id=english_pipeline.id, length_scale = 1.0, pcm=0, audio_format= 0)\n",
    "config_2 = RequestConfig(t2s_pipeline_id=english_pipeline.id, length_scale = 0.5, pcm=0, audio_format= 1)\n",
    "\n",
    "request_1 = SynthesizeRequest(text='Hello', config=config_1)\n",
    "request_2 = SynthesizeRequest(text='How are you?', config=config_2)\n",
    "\n",
    "request = BatchSynthesizeRequest(batch_request = [request_1, request_2])\n",
    "\n",
    "response = client.services.text_to_speech.batch_synthesize(request = request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktULf2b0DiGk"
   },
   "outputs": [],
   "source": [
    "\n",
    "for audio_message in response.batch_response:\n",
    "  display(Audio(audio_message.audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7-VTdUrtZSF"
   },
   "source": [
    "## Get Pipeline\n",
    "\n",
    "In order to get an specific pipeline configuration the GetT2sPipeline method is used. This method received a T2sPipelineId and retrieves a Text2SpeechConfig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "to73X70rtZSF"
   },
   "outputs": [],
   "source": [
    "request = T2sPipelineId(id=english_pipeline.id)\n",
    "pipeline_config = client.services.text_to_speech.get_t2s_pipeline(request=request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkpdKu4O6_b_"
   },
   "source": [
    "## Create Pipeline\n",
    "\n",
    "The server provides a method for creating new pipelines. This can be done with the function CreateT2sPipeline, which receives a Text2SpeechConfig and retrieves a T2sPipelineId."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4yVorW47Hfd"
   },
   "outputs": [],
   "source": [
    "new_inference_config = pipeline_config.inference\n",
    "new_inference_config.composite_inference.text2mel.glow_tts.length_scale = 2\n",
    "request = Text2SpeechConfig(id='brigitte2.0',                           # Pipeline Id\n",
    "                            description=pipeline_config.description,      # Pipeline Description \n",
    "                            active=True,                                  # Pipeline is active or not\n",
    "                            inference=new_inference_config,               # Pipeline Inference configuration\n",
    "                            normalization=pipeline_config.normalization,  # Pipeline Normalization Parameters\n",
    "                            postprocessing=pipeline_config.postprocessing)# Pipeline Postprocessing\n",
    "new_pipeline_id = client.services.text_to_speech.create_t2s_pipeline(request=request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uV0kSvYYNIfq"
   },
   "source": [
    "## Update Pipeline\n",
    "\n",
    "The server provides a method to update a pipeline called UpdateT2sPipeline, receiving a pipeline configuration.\n",
    "\n",
    "In the following example, the retrieved configuration in the previous call is modified and used to update the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txiSzQnkNPf6"
   },
   "outputs": [],
   "source": [
    "pipeline_config.inference.composite_inference.text2mel.glow_tts.length_scale = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMVoLpbxNn1I"
   },
   "outputs": [],
   "source": [
    "client.services.text_to_speech.update_t2s_pipeline(request=pipeline_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FP4Hsy9ctZSG"
   },
   "source": [
    "## Delete Pipeline\n",
    "\n",
    "A pipeline can be deleted with the method DeleteT2sPipeline, receiving a pipeline id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5XH8ArwBtZSG"
   },
   "outputs": [],
   "source": [
    "request = T2sPipelineId(id='brigitte2.0')\n",
    "pipeline_config = client.services.text_to_speech.get_t2s_pipeline(request=request)\n",
    "client.services.text_to_speech.delete_t2s_pipeline(request=request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ondewo_t2s_with_certificate.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
